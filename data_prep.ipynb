{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e44f9ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tifffile\n",
    "import torch \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import ToTensor\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from PIL import Image\n",
    "from utils.data_handlers import *\n",
    "from utils.models import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "# Example usage\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91a5e041",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5e298b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_1, train_artifacts_1= link_label1_to_image('train/image', 'train/label2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99bffd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_0, all_artifacts_0=link_label0_to_image('No_Artifacts','No_Artifacts_label')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "253335fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(all_labels_0.keys())\n",
    "\n",
    "\n",
    "# Split the keys into training and testing sets\n",
    "keys_train, keys_test = train_test_split(keys, test_size=0.2, random_state=42)\n",
    "train_labels_0 = {key: all_labels_0[key] for key in keys_train}\n",
    "train_artifacts_0 = {key: all_artifacts_0[key] for key in keys_train}\n",
    "test_labels_0 = {key: all_labels_0[key] for key in keys_test}\n",
    "test_artifacts_0 = {key: all_artifacts_0[key] for key in keys_test}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9461296",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_1.update(train_labels_0)\n",
    "train_labels=train_labels_1\n",
    "train_artifacts_1.update(train_artifacts_0)\n",
    "train_artifacts=train_artifacts_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b0a2466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347 347\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels),len(train_artifacts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8da9d1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296 296\n"
     ]
    }
   ],
   "source": [
    "test_labels_1, test_artifacts_1=link_label1_to_image('test/image', 'test/label2')\n",
    "print(len(test_labels_1), len(test_artifacts_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cffdb796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347 347\n"
     ]
    }
   ],
   "source": [
    "test_labels_1.update(test_labels_0)\n",
    "test_labels=test_labels_1\n",
    "test_artifacts_1.update(test_artifacts_0)\n",
    "test_artifacts=test_artifacts_1\n",
    "print(len(test_labels),len(test_artifacts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3876e812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "694 694\n"
     ]
    }
   ],
   "source": [
    "test_labels.update(train_labels)\n",
    "total_labels=test_labels\n",
    "test_artifacts.update(train_artifacts)\n",
    "total_artifacts=test_artifacts\n",
    "print(len(test_labels),len(test_artifacts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e21681e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(total_labels.keys())\n",
    "\n",
    "\n",
    "keys_train, keys_temp = train_test_split(keys, test_size=0.3, random_state=42)\n",
    "keys_val, keys_test = train_test_split(keys_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create dictionaries for training, validation, and testing data\n",
    "train_labels_final = {key: total_labels[key] for key in keys_train}\n",
    "train_artifacts_final = {key: total_artifacts[key] for key in keys_train}\n",
    "val_labels = {key: total_labels[key] for key in keys_val}\n",
    "val_artifacts = {key: total_artifacts[key] for key in keys_val}\n",
    "test_labels = {key: total_labels[key] for key in keys_test}\n",
    "test_artifacts = {key: total_artifacts[key] for key in keys_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a529c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'train'\n",
    "train_dict=save_cropped_images_and_labels(train_artifacts_final, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24212c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4365"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ed9ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'val'\n",
    "val_dict=save_cropped_images_and_labels(val_artifacts, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06820559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "936"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3258bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = 'test'\n",
    "test_dict=save_cropped_images_and_labels(test_artifacts, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4355f0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "945"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f6712b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data = CustomDataset(train_dict)\n",
    "test_data = CustomDataset(test_dict)\n",
    "val_data = CustomDataset(val_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55858a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ccf8278",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_keys = list(train_dict.keys())\n",
    "val_keys = list(val_dict.keys())\n",
    "test_keys = list(test_dict.keys())\n",
    "\n",
    "# Sample subsets from the dictionaries\n",
    "subset_train_dict = {k: train_dict[k] for k in random.sample(train_keys, min(100, len(train_keys)))}\n",
    "subset_val_dict = {k: val_dict[k] for k in random.sample(val_keys, min(25, len(val_keys)))}\n",
    "subset_test_dict = {k: test_dict[k] for k in random.sample(test_keys, min(100, len(test_keys)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e90b1a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_train_data = CustomDataset(subset_train_dict)\n",
    "subset_val_data = CustomDataset(subset_val_dict)\n",
    "subset_test_data = CustomDataset(subset_test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9c6ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=len(test_data), shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1430cb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_train_loader = DataLoader(subset_train_data, batch_size=64, shuffle=True)\n",
    "subset_val_loader = DataLoader(subset_val_data, batch_size=16, shuffle=True)\n",
    "subset_test_loader = DataLoader(subset_test_data, batch_size=len(subset_test_data), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b2814c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 0.13839031755924225\n",
      "Epoch 1/1, Train Loss: 0.13839031755924225, Val Loss: 0.1378256231546402\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "model = UNet(pretrained=True)  # Assuming input grayscale images and 2 classes (background and artifacts)\n",
    "criterion = dice_loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Training\n",
    "model.train_model(model, subset_train_loader, subset_val_loader, criterion, optimizer,num_epochs=1,model_save_path='best_train_model.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6cadbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:0.13820317387580872\n"
     ]
    }
   ],
   "source": [
    "model.test_model(model=model, test_loader=test_loader, criterion=criterion, output_folder='test_output')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
